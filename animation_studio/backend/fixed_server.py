#!/usr/bin/env python3
"""
Serveur FastAPI pour g√©n√©ration d'animations compl√®tes avec Wavespeed
Suivant le workflow zseedance.json
"""

import os
import time
import threading
import requests
import openai
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

# Configuration depuis .env
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
WAVESPEED_API_KEY = os.getenv("WAVESPEED_API_KEY")
FAL_API_KEY = os.getenv("FAL_API_KEY")

# Configuration par d√©faut
TEXT_MODEL = os.getenv("TEXT_MODEL", "gpt-4o-mini")
WAVESPEED_MODEL = os.getenv("WAVESPEED_MODEL", "seedance-v1-pro")
CARTOON_STYLE = os.getenv("CARTOON_STYLE", "2D cartoon animation, Disney style, vibrant colors")

# V√©rification des cl√©s API
if not OPENAI_API_KEY or not WAVESPEED_API_KEY:
    print("üí• ERREUR FATALE: Cl√©s API manquantes!")
    print("üîß V√©rifiez votre fichier .env")
    exit(1)

print("‚úÖ Cl√©s API charg√©es avec succ√®s")

# FastAPI app
app = FastAPI(title="Animation Studio API", version="1.0.0")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Stockage des t√¢ches de g√©n√©ration
generation_tasks = {}

@app.get("/health")
def health():
    return {"status": "healthy", "api_keys": {
        "openai": bool(OPENAI_API_KEY),
        "wavespeed": bool(WAVESPEED_API_KEY),
        "fal": bool(FAL_API_KEY)
    }}

@app.get("/themes")
def get_themes():
    return {
        "themes": [
            {"id": "space", "name": "Espace üöÄ", "emoji": "üöÄ"},
            {"id": "ocean", "name": "Oc√©an üåä", "emoji": "üåä"},
            {"id": "forest", "name": "For√™t üå≥", "emoji": "üå≥"},
            {"id": "magic", "name": "Magie ‚ú®", "emoji": "‚ú®"}
        ]
    }

@app.post("/generate")
def generate_animation(request: dict):
    theme = request.get("theme", "space")
    duration = request.get("duration", 30)
    
    # G√©n√©rer un ID unique
    animation_id = f"anim_{int(time.time())}"
    
    # Initialiser la t√¢che
    generation_tasks[animation_id] = {
        "status": "generating",
        "progress": 0,
        "current_step": "üöÄ D√©marrage de la g√©n√©ration...",
        "theme": theme,
        "duration": duration
    }
    
    print(f"üé¨ Nouvelle g√©n√©ration: {animation_id} - Th√®me: {theme} - Dur√©e: {duration}s")
    
    # Lancer la g√©n√©ration en arri√®re-plan
    thread = threading.Thread(
        target=real_generation_process,
        args=(animation_id, theme, duration)
    )
    thread.daemon = True
    thread.start()
    
    return {"animation_id": animation_id, "status": "started"}

def real_generation_process(animation_id: str, theme: str, duration: int):
    """Processus de g√©n√©ration COMPLET suivant zseedance.json"""
    
    global generation_tasks
    task = generation_tasks[animation_id]
    
    try:
        # √âtape 1: G√©n√©ration de l'histoire compl√®te
        task["progress"] = 5
        task["current_step"] = "üìù G√©n√©ration de l'histoire compl√®te..."
        print(f"üìù G√©n√©ration histoire pour {animation_id}")
        
        story = generate_complete_story_sync(theme, duration)
        
        # √âtape 2: Cr√©ation des sc√®nes d√©taill√©es
        task["progress"] = 15
        task["current_step"] = "üé¨ Cr√©ation des sc√®nes d√©taill√©es..."
        print(f"üé¨ Cr√©ation sc√®nes pour {animation_id}")
        
        scenes = generate_detailed_scenes_sync(story, theme, duration)
        
        # √âtape 3: G√©n√©ration des clips vid√©o
        task["progress"] = 25
        task["current_step"] = "üé• G√©n√©ration des clips vid√©o..."
        print(f"üé• G√©n√©ration clips pour {animation_id}")
        
        video_clips = generate_video_clips_sync(scenes, theme)
        
        # √âtape 4: G√©n√©ration audio
        task["progress"] = 70
        task["current_step"] = "üîä G√©n√©ration audio et musique..."
        print(f"üîä G√©n√©ration audio pour {animation_id}")
        
        audio_url = generate_audio_sync(story, theme)
        
        # √âtape 5: Assemblage final
        task["progress"] = 85
        task["current_step"] = "üé¨ Assemblage final de la vid√©o..."
        print(f"üé¨ Assemblage final pour {animation_id}")
        
        final_video_url = assemble_final_video_sync(video_clips, audio_url, duration)
        
        # Terminer la g√©n√©ration
        task["status"] = "completed"
        task["progress"] = 100
        task["current_step"] = "‚úÖ Dessin anim√© complet termin√©!"
        task["result"] = {
            "final_video_url": final_video_url,
            "story": {
                "title": story.get("title", f"Histoire {theme}"),
                "summary": story.get("summary", ""),
                "characters": story.get("characters", []),
                "moral": story.get("moral", ""),
                "target_audience": story.get("target_audience", "Enfants de 3-8 ans")
            },
            "scenes": scenes,
            "theme": theme,
            "duration": duration,
            "real_generation": True,
            "professional_storytelling": True
        }
        
        print(f"üéâ DESSIN ANIM√â COMPLET {animation_id} termin√©!")
        
    except Exception as e:
        print(f"üí• ERREUR G√âN√âRATION: {e}")
        task["status"] = "error"
        task["error"] = str(e)
        task["current_step"] = "‚ùå Erreur g√©n√©ration"

def generate_complete_story_sync(theme: str, duration: int):
    """G√©n√©rer une histoire compl√®te et coh√©rente avec OpenAI (niveau professionnel)"""
    
    # Configuration OpenAI
    openai.api_key = OPENAI_API_KEY
    
    # Prompt pour g√©n√©rer une histoire de niveau professionnel
    story_prompt = f"""Cr√©e une histoire d'animation de {duration} secondes sur le th√®me "{theme}" avec une structure narrative compl√®te comme dans les dessins anim√©s professionnels.

L'histoire doit avoir :
- Une exposition (introduction des personnages et du monde)
- Un d√©veloppement (conflit ou d√©fi √† surmonter)
- Un climax (moment de tension maximale)
- Une r√©solution (fin heureuse et satisfaisante)

Format de r√©ponse JSON :
{{
    "title": "Titre accrocheur de l'histoire",
    "summary": "R√©sum√© complet de l'histoire avec tous les √©l√©ments narratifs",
    "characters": [
        {{
            "name": "Nom du personnage",
            "description": "Description physique et personnalit√©",
            "role": "R√¥le dans l'histoire (protagoniste, antagoniste, etc.)",
            "arc": "√âvolution du personnage dans l'histoire"
        }}
    ],
    "scenes": [
        {{
            "scene_number": 1,
            "title": "Titre de la sc√®ne",
            "description": "Description d√©taill√©e de ce qui se passe",
            "visual_elements": "√âl√©ments visuels sp√©cifiques (d√©cors, actions, expressions)",
            "dialogue": "Dialogues ou narration pour cette sc√®ne",
            "emotions": "√âmotions des personnages et ambiance",
            "duration": {duration // max(4, duration // 8)},
            "narrative_purpose": "R√¥le de cette sc√®ne dans l'histoire (exposition, d√©veloppement, etc.)",
            "transition": "Comment cette sc√®ne se connecte √† la suivante"
        }}
    ],
    "theme": "{theme}",
    "total_duration": {duration},
    "moral": "Message ou le√ßon de l'histoire",
    "target_audience": "Enfants de 3-8 ans"
}}

L'histoire doit √™tre captivante, avec des personnages attachants, des √©motions fortes, et une progression logique qui maintient l'int√©r√™t du d√©but √† la fin."""

    try:
        response = openai.ChatCompletion.create(
            model=TEXT_MODEL,
            messages=[
                {"role": "system", "content": "Tu es un sc√©nariste professionnel sp√©cialis√© dans les dessins anim√©s pour enfants. Tu cr√©es des histoires avec une structure narrative compl√®te, des personnages m√©morables, et des √©motions authentiques."},
                {"role": "user", "content": story_prompt}
            ],
            max_tokens=3000,
            temperature=0.7
        )
        
        story_text = response.choices[0].message.content
        print(f"üìù Histoire professionnelle g√©n√©r√©e: {story_text[:300]}...")
        
        # Parser la r√©ponse JSON
        import json
        try:
            story_data = json.loads(story_text)
            return story_data
        except json.JSONDecodeError:
            print(f"‚ö†Ô∏è  Erreur parsing JSON, utilisation du fallback")
            return create_professional_fallback_story(theme, duration)
            
    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur g√©n√©ration histoire OpenAI: {e}")
        return create_professional_fallback_story(theme, duration)

def create_professional_fallback_story(theme: str, duration: int):
    """Histoire de fallback de niveau professionnel"""
    scenes_count = max(4, duration // 8)  # Plus de sc√®nes pour une meilleure structure
    
    # Cr√©er une structure narrative compl√®te
    scenes = []
    for i in range(scenes_count):
        if i == 0:
            # Exposition
            scene_type = "exposition"
            description = f"Introduction du monde {theme} et des personnages principaux"
        elif i == scenes_count - 1:
            # R√©solution
            scene_type = "resolution"
            description = f"Fin heureuse de l'aventure dans le monde {theme}"
        elif i == scenes_count // 2:
            # Climax
            scene_type = "climax"
            description = f"Le moment le plus intense de l'histoire {theme}"
        else:
            # D√©veloppement
            scene_type = "development"
            description = f"L'histoire se d√©veloppe dans le monde {theme}"
        
        scenes.append({
            "scene_number": i + 1,
            "title": f"Sc√®ne {i+1}: {scene_type.title()}",
            "description": description,
            "visual_elements": f"√âl√©ments visuels riches pour la sc√®ne {i+1}",
            "dialogue": f"Dialogue ou narration pour la sc√®ne {i+1}",
            "emotions": "√âmotions des personnages",
            "duration": duration // scenes_count,
            "narrative_purpose": scene_type,
            "transition": f"Transition vers la sc√®ne suivante"
        })
    
    return {
        "title": f"L'Aventure {theme.title()}",
        "summary": f"Une histoire captivante dans le monde {theme} avec des personnages attachants et une aventure m√©morable",
        "characters": [
            {
                "name": "H√©ros",
                "description": "Personnage principal courageux et amical",
                "role": "protagoniste",
                "arc": "√âvolution vers la maturit√© et le courage"
            }
        ],
        "scenes": scenes,
        "theme": theme,
        "total_duration": duration,
        "moral": "L'amiti√© et le courage triomphent toujours",
        "target_audience": "Enfants de 3-8 ans"
    }

def generate_detailed_scenes_sync(story: dict, theme: str, duration: int):
    """G√©n√©rer des sc√®nes d√©taill√©es bas√©es sur l'histoire professionnelle"""
    
    if "scenes" in story and story["scenes"]:
        # Utiliser les sc√®nes g√©n√©r√©es par OpenAI avec tous les d√©tails
        scenes = []
        for scene_data in story["scenes"]:
            # Cr√©er un prompt visuel riche avec tous les √©l√©ments narratifs
            visual_prompt = f"""{CARTOON_STYLE}, {scene_data['title']}, {scene_data['description']}, {scene_data['visual_elements']}, {scene_data['emotions']}, {scene_data['dialogue']}, {scene_data['narrative_purpose']}, {scene_data['transition']}, colorful, high quality animation, children friendly, professional storytelling, coherent narrative flow"""
            
            scenes.append({
                "id": scene_data["scene_number"],
                "title": scene_data["title"],
                "description": scene_data["description"],
                "duration": scene_data["duration"],
                "visual_prompt": visual_prompt,
                "dialogue": scene_data.get("dialogue", ""),
                "emotions": scene_data.get("emotions", ""),
                "narrative_purpose": scene_data.get("narrative_purpose", ""),
                "transition": scene_data.get("transition", "")
            })
        return scenes
    else:
        # Fallback am√©lior√©
        scenes_count = max(4, duration // 8)
        scenes = []
        for i in range(scenes_count):
            scene_type = ["exposition", "development", "climax", "resolution"][min(i, 3)]
            scenes.append({
                "id": i + 1,
                "title": f"Sc√®ne {i+1}: {scene_type.title()}",
                "description": f"Sc√®ne {i+1} de l'histoire {theme} - {scene_type}",
                "duration": duration / scenes_count,
                "visual_prompt": f"{CARTOON_STYLE}, sc√®ne {i+1} de l'histoire {theme}, {scene_type}, colorful, high quality animation, children friendly, professional storytelling, coherent narrative flow",
                "narrative_purpose": scene_type
            })
        return scenes

def generate_video_clips_sync(scenes: list, theme: str):
    """G√©n√©rer les clips vid√©o pour chaque sc√®ne"""
    
    video_clips = []
    
    for i, scene in enumerate(scenes):
        print(f"üé• G√©n√©ration clip {i+1}/{len(scenes)}...")
        
        # G√©n√©rer un clip pour cette sc√®ne
        clip_url = generate_single_video_clip_sync(scene["visual_prompt"], theme)
        video_clips.append({
            "scene_id": scene["id"],
            "url": clip_url,
            "duration": scene["duration"]
        })
    
    return video_clips

def wait_for_wavespeed_sync(prediction_id: str, headers: dict):
    """Attendre le r√©sultat Wavespeed (version synchrone) - Timeout 10 minutes"""
    print(f"‚è≥ Attente r√©sultat Wavespeed {prediction_id}...")
    for attempt in range(120):  # 10 minutes max
        print(f"üîÑ Tentative {attempt+1}/120 - Attente 5 secondes...")
        time.sleep(5)
        try:
            response = requests.get(
                f"https://api.wavespeed.ai/api/v3/predictions/{prediction_id}/result",
                headers=headers,
                timeout=60
            )
            if response.status_code == 200:
                result = response.json()
                status = result.get("data", {}).get("status", "unknown")
                print(f"üìà Status Wavespeed: {status}")
                if status == "completed":
                    outputs = result.get("data", {}).get("outputs", [])
                    print(f"üîç Outputs: {outputs}")
                    if outputs and len(outputs) > 0:
                        try:
                            if isinstance(outputs[0], str):
                                video_url = outputs[0]
                            elif isinstance(outputs[0], dict):
                                video_url = outputs[0].get("url")
                            else:
                                video_url = str(outputs[0])
                            if video_url:
                                print(f"‚úÖ Clip g√©n√©r√© avec succ√®s!")
                                print(f"üé¨ URL: {video_url[:50]}...")
                                return video_url
                        except Exception as e:
                            print(f"‚ö†Ô∏è  Erreur extraction outputs: {e}")
                    try:
                        video_url = result.get("data", {}).get("video_url") or result.get("video_url")
                        if video_url:
                            print(f"‚úÖ Clip g√©n√©r√© avec succ√®s!")
                            print(f"üé¨ URL: {video_url[:50]}...")
                            return video_url
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Erreur extraction video_url: {e}")
                    print(f"üîç R√©ponse compl√®te: {result}")
                    raise Exception("Pas d'URL vid√©o dans la r√©ponse")
                elif status == "failed":
                    error_msg = result.get("data", {}).get("error", "Erreur inconnue")
                    raise Exception(f"G√©n√©ration Wavespeed √©chou√©e: {error_msg}")
                elif status in ["processing", "queued", "starting"]:
                    print(f"‚è≥ En cours... ({status})")
                    continue
            else:
                print(f"‚ö†Ô∏è  Status polling: {response.status_code}")
                continue
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur polling: {e}")
            continue
    raise Exception("Timeout Wavespeed apr√®s 10 minutes - g√©n√©ration √©chou√©e")

def generate_single_video_clip_sync(prompt: str, theme: str):
    """G√©n√©rer un seul clip vid√©o avec Wavespeed (format paysage)"""
    headers = {
        "Authorization": f"Bearer {WAVESPEED_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "aspect_ratio": "16:9",  # Paysage
        "duration": 10,
        "prompt": prompt[:500]
    }
    try:
        response = requests.post(
            "https://api.wavespeed.ai/api/v3/bytedance/seedance-v1-pro-t2v-480p",
            headers=headers,
            json=data,
            timeout=120
        )
        if response.status_code == 200:
            result = response.json()
            prediction_id = result.get("data", {}).get("id") or result.get("id")
            if prediction_id:
                return wait_for_wavespeed_sync(prediction_id, headers)
            else:
                raise Exception("Pas d'ID de pr√©diction Wavespeed")
        else:
            raise Exception(f"Erreur Wavespeed {response.status_code}: {response.text}")
    except Exception as e:
        print(f"üí• Erreur clip vid√©o: {e}")
        raise Exception(f"G√©n√©ration clip √©chou√©e: {e}")

def generate_audio_sync(story: dict, theme: str):
    """G√©n√©rer l'audio professionnel avec narration, dialogue et musique d'ambiance"""
    
    # Cr√©er un script audio bas√© sur l'histoire compl√®te
    audio_script = f"Histoire: {story.get('title', 'Aventure')}\n\n"
    
    if "summary" in story:
        audio_script += f"R√©sum√©: {story['summary']}\n\n"
    
    if "characters" in story:
        audio_script += "Personnages:\n"
        for char in story["characters"]:
            audio_script += f"- {char['name']}: {char['description']}\n"
        audio_script += "\n"
    
    if "scenes" in story:
        audio_script += "Sc√®nes:\n"
        for scene in story["scenes"]:
            audio_script += f"Sc√®ne {scene['scene_number']}: {scene.get('title', '')}\n"
            audio_script += f"Dialogue: {scene.get('dialogue', '')}\n"
            audio_script += f"√âmotions: {scene.get('emotions', '')}\n\n"
    
    if "moral" in story:
        audio_script += f"Le√ßon: {story['moral']}\n"
    
    # Cr√©er un prompt pour la musique d'ambiance
    music_prompt = f"Musique d'ambiance pour une histoire d'animation sur le th√®me {theme}. "
    music_prompt += "Style: m√©lodique, adapt√© aux enfants, avec des variations selon les √©motions des sc√®nes. "
    music_prompt += "Inclure des sons d'ambiance coh√©rents avec le th√®me et l'histoire."
    
    headers = {
        "Authorization": f"Key {FAL_API_KEY}",
        "Content-Type": "application/json"
    }
    
    # Pour l'instant, simuler la g√©n√©ration audio professionnelle
    print(f"üîä Script audio professionnel g√©n√©r√©:")
    print(f"üìù {audio_script[:200]}...")
    print(f"üéµ {music_prompt}")
    
    # TODO: Impl√©menter la vraie g√©n√©ration audio avec FAL AI ou OpenAI TTS
    # Pour l'instant, retourner une URL factice
    return "https://example.com/professional_audio.mp3"

def assemble_final_video_sync(video_clips: list, audio_url: str, duration: int):
    """Assembler la vid√©o finale avec FAL FFmpeg (strict, sans fallback)"""
    if not video_clips:
        raise Exception("Aucun clip vid√©o disponible")
    
    print(f"üé¨ Assemblage de {len(video_clips)} clips...")
    
    if len(video_clips) == 1:
        final_url = video_clips[0]["url"]
        print(f"‚úÖ Un seul clip, utilisation directe: {final_url}")
        return final_url
    
    # Format de payload pour concat√©nation avec FAL FFmpeg
    keyframes = []
    timestamp = 0
    for clip in video_clips:
        keyframes.append({
            "url": clip["url"],
            "timestamp": timestamp,
            "duration": int(clip["duration"])
        })
        timestamp += int(clip["duration"])
    
    payload = {
        "tracks": [
            {
                "id": "1",
                "type": "video",
                "keyframes": keyframes
            }
        ]
    }
    
    headers = {
        "Authorization": f"Key {FAL_API_KEY}",
        "Content-Type": "application/json"
    }
    
    try:
        print(f"üì§ Envoi √† FAL FFmpeg: {payload}")
        response = requests.post(
            "https://queue.fal.run/fal-ai/ffmpeg-api/compose",  # Endpoint original
            headers=headers,
            json=payload,
            timeout=180
        )
        print(f"üì• R√©ponse FAL: {response.status_code} - {response.text}")
        if response.status_code == 200:
            result = response.json()
            request_id = result.get("request_id") or result.get("id")
            if not request_id:
                raise Exception("Pas d'ID de requ√™te FAL FFmpeg")
            return wait_for_fal_ffmpeg_simple(request_id, headers)
        else:
            raise Exception(f"Erreur FAL FFmpeg {response.status_code}: {response.text}")
    except Exception as e:
        print(f"üí• Erreur assemblage: {e}")
        raise Exception(f"Assemblage vid√©o √©chou√©: {e}")

def wait_for_fal_ffmpeg_simple(request_id: str, headers: dict):
    """Polling simplifi√© pour FAL FFmpeg (avec d√©tection video_url m√™me si status inconnu)"""
    for attempt in range(30):  # 2.5 minutes max
        print(f"üîÑ Polling FAL {request_id}... ({attempt+1}/30)")
        try:
            response = requests.get(
                f"https://queue.fal.run/fal-ai/ffmpeg-api/requests/{request_id}",
                headers=headers,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                print(f"üìù R√©ponse FAL compl√®te: {result}")  # Debug complet
                status = result.get("status", "unknown")
                print(f"üìà Status: {status}")
                # Correction : si video_url pr√©sent, on le retourne imm√©diatement
                video_url = result.get("video_url")
                if video_url:
                    print(f"‚úÖ Vid√©o assembl√©e (video_url d√©tect√©): {video_url}")
                    return video_url
                if status == "completed":
                    video_url = result.get("output", {}).get("video") or result.get("output")
                    if video_url:
                        print(f"‚úÖ Vid√©o assembl√©e: {video_url}")
                        return video_url
                elif status == "failed":
                    print(f"‚ùå FAL √©chou√©: {result}")
                    raise Exception(f"FAL √©chou√©: {result}")
                elif status == "unknown" and result.get("error"):
                    print(f"‚ùå Erreur FAL: {result.get('error')}")
                    raise Exception(f"Erreur FAL: {result.get('error')}")
            time.sleep(5)
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur polling: {e}")
            time.sleep(5)
    raise Exception("Timeout FAL FFmpeg")

@app.get("/status/{animation_id}")
def get_status(animation_id: str):
    if animation_id not in generation_tasks:
        raise HTTPException(status_code=404, detail="Animation non trouv√©e")
    
    return generation_tasks[animation_id]

if __name__ == "__main__":
    import uvicorn
    print("üöÄ Lancement du serveur Animation Studio COMPLET...")
    print(f"üîë OpenAI: {'‚úÖ' if OPENAI_API_KEY else '‚ùå'}")
    print(f"üîë Wavespeed: {'‚úÖ' if WAVESPEED_API_KEY else '‚ùå'}")
    print(f"üîë FAL: {'‚úÖ' if FAL_API_KEY else '‚ùå'}")
    uvicorn.run(app, host="0.0.0.0", port=8011) 